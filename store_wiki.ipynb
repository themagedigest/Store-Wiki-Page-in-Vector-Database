{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import os, getpass\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from pinecone import Pinecone\n",
    "from urllib.parse import urlparse, unquote\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from collections import namedtuple\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Fetch Wikipedia Page Content\n",
    "def fetch_wikipedia_page(page_identifier):\n",
    "    try:\n",
    "        # Set custom user-agent\n",
    "        wikipedia.set_lang(\"en\")  # Ensure we are using the English language\n",
    "        wikipedia.set_user_agent(\"somevaluehere/1.0 (tes1223434@example.com)\")  # Custom user agent\n",
    "        \n",
    "        # Check if input is a URL or a title\n",
    "        if page_identifier.startswith(\"http\"):\n",
    "            # Extract the title from the URL\n",
    "            path = urlparse(page_identifier).path\n",
    "            title = unquote(path.split('/')[-1])  # Decode and get the last part of the path\n",
    "        else:\n",
    "            # Use the identifier as the title\n",
    "            title = page_identifier.strip().replace(\"\\\"\", \"\")  # Sanitize input\n",
    "            \n",
    "        # Attempt to fetch the page\n",
    "        page = wikipedia.page(title)\n",
    "        return page.content  # Return the full text of the page\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        print(f\"Disambiguation error for identifier '{page_identifier}'. Options: {e.options}\")\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        print(f\"Page '{page_identifier}' not found. Please check the title or URL.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pinecone and Store Vectors\n",
    "def store_embeddings_in_pinecone(page_title, documents, index_name):\n",
    "    # Initialize Pinecone\n",
    "    pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])\n",
    "    \n",
    "    # Create a Pinecone index if it doesn't exist\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        print(\"wiki-index Index does not exist, creating...\")\n",
    "        # Define the spec using ServerlessSpec\n",
    "        spec = ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")\n",
    "        pc.create_index(name=index_name, spec=spec, dimension=1536)\n",
    "    \n",
    "    # Get embeddings for the page\n",
    "    embeddings = OpenAIEmbeddings(api_key=os.environ['OPENAI_API_KEY'])\n",
    "    \n",
    "    # Upsert the vector into Pinecone\n",
    "    PineconeVectorStore.from_documents(documents = documents, embedding = embeddings, index_name = index_name)\n",
    "    print(f\"Successfully stored the {page_title} page in Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored the Amazon_(company) page in Pinecone.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "page_title = \"Amazon_(company)\"  # Replace with the Wikipedia page you want\n",
    "page_text = fetch_wikipedia_page(page_title)\n",
    "\n",
    "# Define the named tuple\n",
    "Document = namedtuple(\"Document\", [\"page_content\", \"metadata\"])\n",
    "\n",
    "# Create a list of named tuples (documents)\n",
    "documents = [Document(page_content=page_text, metadata={\"title\": page_title})]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "document_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "store_embeddings_in_pinecone(page_title, document_chunks, index_name = \"wiki-index\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
